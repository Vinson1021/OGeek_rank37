{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "stdi, stdo, stde = sys.stdin, sys.stdout, sys.stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "sys.stdin, sys.stdout, sys.stderr = stdi, stdo, stde\n",
    "\n",
    "def bbb(a,b):\n",
    "    c = {}\n",
    "    for i,j in eval(a).items():\n",
    "        c[i.lower()] = j\n",
    "\n",
    "    if b.lower() in c:\n",
    "        if float(c[b.lower()])>0.1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_data = pd.read_table('data/oppo_round1_train_20180929.txt',names=['prefix','query_prediction','title','tag','label'],header=None,encoding='utf-8').astype(str)\n",
    "train_data = pd.concat([train_data,pd.read_table('data26/oppo_round1_train_20180926.txt',names=['prefix','query_prediction','title','tag','label'],header=None,encoding='utf-8').astype(str)])\n",
    "val_data = pd.read_table('data/oppo_round1_vali_20180929.txt',names=['prefix','query_prediction','title','tag','label'],header=None,encoding='utf-8').astype(str)\n",
    "test_data = pd.read_table('data/oppo_round1_test_A_20180929.txt',names=['prefix','query_prediction','title','tag','label'],header=None,encoding='utf-8').astype(str)\n",
    "\n",
    "train_data = train_data[train_data['label']!='音乐']\n",
    "# train_data = pd.concat([train_data,val_data])\n",
    "train_data['label'] = train_data['label'].apply(lambda x:int(x))\n",
    "val_data['label'] = val_data['label'].apply(lambda x:int(x))\n",
    "train_data['prefix_num'] = train_data['prefix'].apply(lambda x:len(x))\n",
    "train_data['title_num'] = train_data['title'].apply(lambda x:len(x))\n",
    "val_data['prefix_num'] = val_data['prefix'].apply(lambda x:len(x))\n",
    "val_data['title_num'] = val_data['title'].apply(lambda x:len(x))\n",
    "test_data['prefix_num'] = test_data['prefix'].apply(lambda x:len(x))\n",
    "test_data['title_num'] = test_data['title'].apply(lambda x:len(x))\n",
    "\n",
    "test_data['in_query_big'] = test_data.apply(lambda x:bbb(x['query_prediction'],x['title']),axis=1)\n",
    "\n",
    "\n",
    "temp1 = train_data.groupby(['prefix','title','tag'],as_index=False)['label'].agg({'click1':'sum','count1':'count','ctr1':'mean'})\n",
    "temp2 = train_data.groupby(['prefix','title'],as_index=False)['label'].agg({'click2':'sum','count2':'count','ctr2':'mean'})\n",
    "temp3 = train_data.groupby(['prefix','tag'],as_index=False)['label'].agg({'click3':'sum','count3':'count','ctr3':'mean'})\n",
    "temp4 = train_data.groupby(['title','tag'],as_index=False)['label'].agg({'click4':'sum','count4':'count','ctr4':'mean'})\n",
    "temp5 = train_data.groupby('prefix',as_index=False)['label'].agg({'click5':'sum','count5':'count','ctr5':'mean'})\n",
    "temp6 = train_data.groupby('title',as_index=False)['label'].agg({'click6':'sum','count6':'count','ctr6':'mean'})\n",
    "temp7 = train_data.groupby('tag',as_index=False)['label'].agg({'click7':'sum','count7':'count','ctr7':'mean'})\n",
    "temp8 = train_data.groupby(['prefix_num','title_num','tag'],as_index=False)['label'].agg({'click8':'sum','count8':'count','ctr8':'mean'})\n",
    "\n",
    "a = pd.merge(train_data,temp1,on=['prefix','title','tag'],how='left')\n",
    "b = pd.merge(train_data,temp2,on=['prefix','title'],how='left')\n",
    "c = pd.merge(train_data,temp3,on=['prefix','tag'],how='left')\n",
    "d = pd.merge(train_data,temp4,on=['title','tag'],how='left')\n",
    "e = pd.merge(train_data,temp5,on='prefix',how='left')\n",
    "f = pd.merge(train_data,temp6,on='title',how='left')\n",
    "g = pd.merge(train_data,temp7,on='tag',how='left')\n",
    "h = pd.merge(train_data,temp8,on=['prefix_num','title_num','tag'],how='left')\n",
    "\n",
    "a['ctr2'] = b['ctr2']\n",
    "a['ctr3'] = c['ctr3']\n",
    "a['ctr4'] = d['ctr4']\n",
    "a['ctr5'] = e['ctr5']\n",
    "a['ctr6'] = f['ctr6']\n",
    "a['ctr7'] = g['ctr7']\n",
    "a['ctr8'] = h['ctr8']\n",
    "\n",
    "a['count2'] = b['count2']\n",
    "a['count3'] = c['count3']\n",
    "a['count4'] = d['count4']\n",
    "a['count5'] = e['count5']\n",
    "a['count6'] = f['count6']\n",
    "a['count7'] = g['count7']\n",
    "\n",
    "a = a.fillna(0)\n",
    "\n",
    "train_data = a\n",
    "\n",
    "a = pd.merge(val_data,temp1,on=['prefix','title','tag'],how='left')\n",
    "b = pd.merge(val_data,temp2,on=['prefix','title'],how='left')\n",
    "c = pd.merge(val_data,temp3,on=['prefix','tag'],how='left')\n",
    "d = pd.merge(val_data,temp4,on=['title','tag'],how='left')\n",
    "e = pd.merge(val_data,temp5,on='prefix',how='left')\n",
    "f = pd.merge(val_data,temp6,on='title',how='left')\n",
    "g = pd.merge(val_data,temp7,on='tag',how='left')\n",
    "h = pd.merge(val_data,temp8,on=['prefix_num','title_num','tag'],how='left')\n",
    "\n",
    "a['ctr2'] = b['ctr2']\n",
    "a['ctr3'] = c['ctr3']\n",
    "a['ctr4'] = d['ctr4']\n",
    "a['ctr5'] = e['ctr5']\n",
    "a['ctr6'] = f['ctr6']\n",
    "a['ctr7'] = g['ctr7']\n",
    "a['ctr8'] = h['ctr8']\n",
    "\n",
    "a['count2'] = b['count2']\n",
    "a['count3'] = c['count3']\n",
    "a['count4'] = d['count4']\n",
    "a['count5'] = e['count5']\n",
    "a['count6'] = f['count6']\n",
    "a['count7'] = g['count7']\n",
    "\n",
    "a = a.fillna(0)\n",
    "\n",
    "val_data = a\n",
    "\n",
    "a = pd.merge(test_data,temp1,on=['prefix','title','tag'],how='left')\n",
    "b = pd.merge(test_data,temp2,on=['prefix','title'],how='left')\n",
    "c = pd.merge(test_data,temp3,on=['prefix','tag'],how='left')\n",
    "d = pd.merge(test_data,temp4,on=['title','tag'],how='left')\n",
    "e = pd.merge(test_data,temp5,on='prefix',how='left')\n",
    "f = pd.merge(test_data,temp6,on='title',how='left')\n",
    "g = pd.merge(test_data,temp7,on='tag',how='left')\n",
    "h = pd.merge(test_data,temp8,on=['prefix_num','title_num','tag'],how='left')\n",
    "\n",
    "a['ctr2'] = b['ctr2']\n",
    "a['ctr3'] = c['ctr3']\n",
    "a['ctr4'] = d['ctr4']\n",
    "a['ctr5'] = e['ctr5']\n",
    "a['ctr6'] = f['ctr6']\n",
    "a['ctr7'] = g['ctr7']\n",
    "a['ctr8'] = h['ctr8']\n",
    "\n",
    "a['count2'] = b['count2']\n",
    "a['count3'] = c['count3']\n",
    "a['count4'] = d['count4']\n",
    "a['count5'] = e['count5']\n",
    "a['count6'] = f['count6']\n",
    "a['count7'] = g['count7']\n",
    "\n",
    "a = a.fillna(0)\n",
    "\n",
    "test_data = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999998, 18)\n",
      "(50000, 18)\n",
      "LGB test\n",
      "[1]\tvalid_0's binary_logloss: 0.647279\tvalid_0's auc: 0.77138\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.611348\tvalid_0's auc: 0.771414\n",
      "[3]\tvalid_0's binary_logloss: 0.582999\tvalid_0's auc: 0.800281\n",
      "[4]\tvalid_0's binary_logloss: 0.560061\tvalid_0's auc: 0.797436\n",
      "[5]\tvalid_0's binary_logloss: 0.540954\tvalid_0's auc: 0.80133\n",
      "[6]\tvalid_0's binary_logloss: 0.526474\tvalid_0's auc: 0.800317\n",
      "[7]\tvalid_0's binary_logloss: 0.515281\tvalid_0's auc: 0.799166\n",
      "[8]\tvalid_0's binary_logloss: 0.506429\tvalid_0's auc: 0.799071\n",
      "[9]\tvalid_0's binary_logloss: 0.499985\tvalid_0's auc: 0.798263\n",
      "[10]\tvalid_0's binary_logloss: 0.495405\tvalid_0's auc: 0.79829\n",
      "[11]\tvalid_0's binary_logloss: 0.492515\tvalid_0's auc: 0.798315\n",
      "[12]\tvalid_0's binary_logloss: 0.491075\tvalid_0's auc: 0.79727\n",
      "[13]\tvalid_0's binary_logloss: 0.491056\tvalid_0's auc: 0.796272\n",
      "[14]\tvalid_0's binary_logloss: 0.491333\tvalid_0's auc: 0.796425\n",
      "[15]\tvalid_0's binary_logloss: 0.493095\tvalid_0's auc: 0.795742\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_logloss: 0.540954\tvalid_0's auc: 0.80133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=50, min_split_gain=0.0, n_estimators=5000,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=2018,\n",
       "        reg_alpha=0.0, reg_lambda=1, silent=True, subsample=0.7,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "       u'prefix_num', u'title_num', u'count1', u'ctr1',\n",
    "       u'click1', u'ctr2', u'ctr3', u'ctr4', u'ctr5', u'ctr6', u'ctr7',\n",
    "       u'ctr8', u'count2', u'count3', u'count4', u'count5', u'count6',\n",
    "       u'count7']\n",
    "\n",
    "train_y = train_data['label']\n",
    "train_x = train_data[features]\n",
    "val_y = val_data['label']\n",
    "val_x = val_data[features]\n",
    "# test = test_data[features]\n",
    "\n",
    "print train_x.shape\n",
    "print val_x.shape\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"LGB test\")\n",
    "clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "    max_depth=-1, n_estimators=5000, objective='binary',\n",
    "    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "    learning_rate=0.1, min_child_weight=50, random_state=2018, n_jobs=-1\n",
    ")\n",
    "clf.fit(train_x, train_y, eval_set=[(val_x, val_y)], \n",
    "        eval_metric={'binary_logloss','auc'},early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999998, 18)\n",
      "LGB test\n",
      "[1]\ttraining's multi_logloss: 0.68743\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.68827\tvalid_1's f1_score: 0.786572\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's multi_logloss: 0.681827\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.683507\tvalid_1's f1_score: 0.786572\n",
      "[3]\ttraining's multi_logloss: 0.676334\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.678854\tvalid_1's f1_score: 0.786572\n",
      "[4]\ttraining's multi_logloss: 0.670948\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.674309\tvalid_1's f1_score: 0.786572\n",
      "[5]\ttraining's multi_logloss: 0.665666\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.669868\tvalid_1's f1_score: 0.786572\n",
      "[6]\ttraining's multi_logloss: 0.660485\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.665528\tvalid_1's f1_score: 0.786572\n",
      "[7]\ttraining's multi_logloss: 0.655404\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.661287\tvalid_1's f1_score: 0.786572\n",
      "[8]\ttraining's multi_logloss: 0.650419\ttraining's f1_score: 0.848124\tvalid_1's multi_logloss: 0.657141\tvalid_1's f1_score: 0.786572\n",
      "[9]\ttraining's multi_logloss: 0.645527\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.653089\tvalid_1's f1_score: 0.786853\n",
      "[10]\ttraining's multi_logloss: 0.640727\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.649128\tvalid_1's f1_score: 0.786853\n",
      "[11]\ttraining's multi_logloss: 0.636016\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.645256\tvalid_1's f1_score: 0.786853\n",
      "[12]\ttraining's multi_logloss: 0.631391\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.641471\tvalid_1's f1_score: 0.786853\n",
      "[13]\ttraining's multi_logloss: 0.626852\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.637771\tvalid_1's f1_score: 0.786853\n",
      "[14]\ttraining's multi_logloss: 0.622395\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.634153\tvalid_1's f1_score: 0.786853\n",
      "[15]\ttraining's multi_logloss: 0.618019\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.630615\tvalid_1's f1_score: 0.786853\n",
      "[16]\ttraining's multi_logloss: 0.613721\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.627156\tvalid_1's f1_score: 0.786853\n",
      "[17]\ttraining's multi_logloss: 0.6095\ttraining's f1_score: 0.846822\tvalid_1's multi_logloss: 0.623773\tvalid_1's f1_score: 0.784461\n",
      "[18]\ttraining's multi_logloss: 0.605355\ttraining's f1_score: 0.846822\tvalid_1's multi_logloss: 0.620467\tvalid_1's f1_score: 0.784461\n",
      "[19]\ttraining's multi_logloss: 0.601282\ttraining's f1_score: 0.846822\tvalid_1's multi_logloss: 0.617232\tvalid_1's f1_score: 0.784461\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.645527\ttraining's f1_score: 0.848172\tvalid_1's multi_logloss: 0.653089\tvalid_1's f1_score: 0.786853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "def f1_score_vali(preds, data_vali):\n",
    "    labels = data_vali.get_label()\n",
    "    preds = np.argmax(preds.reshape(2, -1), axis=0)\n",
    "    score_vali = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    return 'f1_score', score_vali, True\n",
    "\n",
    "features = [\n",
    "       u'prefix_num', u'title_num', u'count1', u'ctr1',\n",
    "       u'click1', u'ctr2', u'ctr3', u'ctr4', u'ctr5', u'ctr6', u'ctr7',\n",
    "       u'ctr8', u'count2', u'count3', u'count4', u'count5', u'count6',\n",
    "       u'count7']\n",
    "\n",
    "train_y = train_data['label']\n",
    "train_x = train_data[features]\n",
    "val_y = val_data['label']\n",
    "val_x = val_data[features]\n",
    "\n",
    "print train_x.shape\n",
    "print(\"LGB test\")\n",
    "params={\n",
    "    \"learning_rate\":0.01,\n",
    "    \"lambda_l1\":0.1,\n",
    "    \"lambda_l2\":0.2,\n",
    "    \"max_depth\":4,\n",
    "    \"objective\":\"multiclass\",\n",
    "    \"num_class\":2,\n",
    "    \"silent\":True,\n",
    "}\n",
    "t_data = lgb.Dataset(train_x, label=train_y)\n",
    "v_data = lgb.Dataset(val_x, label=val_y)\n",
    "clf1=lgb.train(params,t_data,num_boost_round=1000,valid_sets=[t_data,v_data],\n",
    "              early_stopping_rounds=10,feval=f1_score_vali,verbose_eval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37341618670809335\n",
      "0.3717\n"
     ]
    }
   ],
   "source": [
    "print train_data.label.mean()\n",
    "print val_data.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "汽车           37010\n",
       "淘宝           20605\n",
       "作            17656\n",
       "快            15691\n",
       "汽车之家         15653\n",
       "百            15438\n",
       "京东           12902\n",
       "作业帮           9917\n",
       "申通            9847\n",
       "抖音            9818\n",
       "汽             9484\n",
       "爱奇艺           9195\n",
       "小米            9074\n",
       "美团            9011\n",
       "安             8495\n",
       "高             8447\n",
       "12306         8353\n",
       "中国            8238\n",
       "车             7554\n",
       "酷             7293\n",
       "唐家            7053\n",
       "陌陌            6988\n",
       "支             6930\n",
       "天             6372\n",
       "天气            6314\n",
       "qq            6150\n",
       "全民            6129\n",
       "中通快递          5828\n",
       "双色            5623\n",
       "火             5566\n",
       "             ...  \n",
       "联络               1\n",
       "请别忘记我            1\n",
       "侍魂2              1\n",
       "何氏眼              1\n",
       "五声调式             1\n",
       "儿童正常视力           1\n",
       "交通银行信用卡官网        1\n",
       "艾叶泡水             1\n",
       "Lolit            1\n",
       "杨科               1\n",
       "猪脸肉              1\n",
       "谭仲               1\n",
       "流行性感             1\n",
       "二里头              1\n",
       "婚姻测试             1\n",
       "药流多久能            1\n",
       "18650            1\n",
       "面条会              1\n",
       "H1Z              1\n",
       "湖南理工职业技术         1\n",
       "4471             1\n",
       "混沌仙              1\n",
       "有些爱情             1\n",
       "食人魔              1\n",
       "qq皮肤             1\n",
       "阴道软胶             1\n",
       "超华               1\n",
       "常州技              1\n",
       "放环后多久可以同房        1\n",
       "天津电视             1\n",
       "Name: prefix, Length: 191326, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.prefix.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "test_data['label'] = clf.predict(test_data[features])\n",
    "test_data['label'].to_csv('sub/sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
